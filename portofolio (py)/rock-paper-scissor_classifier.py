# -*- coding: utf-8 -*-
"""Copy of JST_CNN_UTS_Kelompok 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HrE1OhJpdfNX5I_YMLCjkw3RJPXXj7HE

# CNN based classifier for Rock-Paper-Scissors dataset
- The input layer accepts 150x150 with 3 bytes color as the input shape, so the image will need to be resized accordingly
- The rps dataset is unlabeled data, ImageDataGenerator will be used to automatically label it.
- The dataset used in this notebook is created by Laurence Moroney (laurencemoroney.com).
- Desired accuracy AND validation_accuracy > 83%

## Preparation
"""

# import necessary libraries

import urllib.request # to get dataset from link and download to directory
import zipfile # unzip files
import tensorflow as tf # tf module for ML
import os
import numpy as np
from tensorflow import keras
from keras.preprocessing.image import ImageDataGenerator

# download the dataset
data_url = 'https://github.com/dicodingacademy/assets/releases/download/release-rps/rps.zip'
urllib.request.urlretrieve(data_url, 'rps.zip')

# Extract zip file
local_file = 'rps.zip'
zip_ref = zipfile.ZipFile(local_file, 'r')
zip_ref.extractall('data/')
zip_ref.close()

"""## Display Dataset Images"""

# Code to take a look at some of the images
rocks = os.listdir('data/rps/rock')
papers = os.listdir('data/rps/paper')
scissors = os.listdir('data/rps/scissors')

print('Total training rock images', len(rocks))
print('First 10 files : ', rocks[:10])

print('Total training Paper images', len(papers))
print('First 10 files : ', papers[:10])

print('Total training Scissors images', len(scissors))
print('First 10 files : ', scissors[:10])

# Commented out IPython magic to ensure Python compatibility.
# display the images

# %matplotlib inline

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

pic_index = 4

next_rock = [os.path.join('data/rps/rock', fname) for fname in rocks[pic_index-4:pic_index]]
next_paper = [os.path.join('data/rps/paper', fname) for fname in papers[pic_index-4:pic_index]]
next_scissors = [os.path.join('data/rps/scissors', fname) for fname in scissors[pic_index-4:pic_index]]

plt.figure(figsize=(12, 12))

for i, img_path in enumerate(next_rock+next_paper+next_scissors):
  plt.subplot(3, 4, i+1)
  img = mpimg.imread(img_path)
  plt.imshow(img)
  plt.title(img_path)
  plt.axis('On') # gridlines off

plt.tight_layout()
plt.show()

"""## Augmentation and Normalize The Data"""

# Split the dataset to training and validation

BASE_DIR = "data/rps/" # prepare base directory of all the images
#VALIDATION_DIR = "data/rps/"

# Object to augment data for training
# Augmentation process incclude rotation, flip, shear to widen variation
# more variation will increase the model learning process and understanding of the image

training_datagen = ImageDataGenerator(
        rescale=1. / 255, # normalize image
        rotation_range=40, # rotate scenario until 40 degree
        horizontal_flip=True, # flip horizontally
        shear_range=0.2, # crop images until 0.2 from original
        zoom_range=0.2, # zoom image until 0.2 from original
        fill_mode='nearest', # fill empty pixels with the value of the nearest ones
        #validation_split=0.2 # split with 80:20 ratio
        )

# Normalize the images for validation process
validation_datagen = ImageDataGenerator(rescale=1./255, #validation_split=0.2
                                        ) # normalize the validation data

# Generator for both process
# For rps dataset the class mode is 'categorical'

train_generator = training_datagen.flow_from_directory(BASE_DIR,
                                                       class_mode='categorical', # for multivariate dataset
                                                       batch_size=64,
                                                       target_size=(150, 150), # resized dataset
                                                       shuffle=True,
                                                       #subset='training' # label to training portion
                                                       )

val_generator = validation_datagen.flow_from_directory(BASE_DIR,
                                                       class_mode='categorical',
                                                       batch_size=32,
                                                       target_size=(150, 150),
                                                       shuffle=True,
                                                       #subset='validation'
                                                       )

"""## Model Architecture"""

# Build the model

model = tf.keras.models.Sequential([
        # The input shape is the desired size of the image with 3 bytes color of rgb
        # First convolution layer
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
        tf.keras.layers.MaxPool2D(2, 2),
        # Second convolution layer
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPool2D(2, 2),
        # Third convolution layer ## add
        # tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        # tf.keras.layers.MaxPool2D(2, 2),
        # Flatten the results to feed into a DNN
        tf.keras.layers.Flatten(),
        # tf.keras.layers.Dropout(0.3), # add
        # 512 neuron hidden layer
        tf.keras.layers.Dense(512, activation='relu'),
        # tf.keras.layers.Dense(128, activation='relu'), # add
        tf.keras.layers.Dense(3, activation='softmax')
    ])

model.summary()

"""## Compile and Fit The Model"""

# Create callback method to minimize running time
class myCallback(tf.keras.callbacks.Callback):
        def on_epoch_end(self, epoch, logs={}):
            if (logs.get('val_accuracy') >= 0.95):
                print('\nAccuracy reached above 90%! Stopping training...')
                self.model.stop_training = True

# Compile the model with loss, optimizer and metric configuration
model.compile(loss='categorical_crossentropy', # the data is multivariate
              optimizer='rmsprop', #Coba lagi pake rms prop, tadi adam
              metrics=['accuracy'])

# Train and fit the model
history = model.fit(train_generator,
                    #steps_per_epoch=20, #coba lagi epoch 25
                    validation_data=val_generator,
                    #validation_steps=5,
                    epochs=25,
                    verbose=1,
                    callbacks=[myCallback()]
                    )

# Take a look at the last accuracy and loss

print("Accuracy reached: ", history.history['accuracy'][slice(-1,None)])
print("Validation Accuracy reached: ", history.history['val_accuracy'][slice(-1,None)])
print("Loss reached: ", history.history['loss'][slice(-1,None)])
print("Validation Loss reached: ", history.history['val_loss'][slice(-1,None)])

val_loss, val_accuracy = model.evaluate(val_generator, verbose=2)

print(val_accuracy)

# Save the model result in h5 file
model.save("rps.h5")

"""## Visualize Result"""

# Visualize the result
# Variable to get the result from the training process
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

# set the epoch range
epoch_range = range(len(acc))

# Plot accuracy
#plt.figure(figsize=(10, 8))
#plt.subplot(131)
plt.plot(epoch_range, acc, label='Training Accuracy')
plt.plot(epoch_range, val_acc, label='Validation Accuracy')
plt.legend(loc='best')
plt.title('Training and Validation Accuracy')
plt.figure()

# Plot loss
#plt.subplot(1, 2, 2)
plt.plot(epoch_range, loss, label='Training Loss', color='m')
plt.plot(epoch_range, val_loss, label='Validation Loss', color='g')
plt.legend(loc=0)
plt.title('Training and Validation Loss')
plt.figure()

# Plot Training
#plt.subplot(1, 2, 3)
plt.plot(epoch_range, acc, label='Training Accuracy', color='y')
plt.plot(epoch_range, loss, label='Training Loss', color='r')
plt.legend(loc='best')
plt.title('Training Accuracy and Loss')
plt.figure()

plt.show()

"""## Evaluate The Model"""

# Commented out IPython magic to ensure Python compatibility.
# Evaluate using new images
# import libraries
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt

# ensure the image will be displayed with graph
# %matplotlib inline

# Upload images
uploaded = files.upload()

# Predict for all uploaded images
for fn in uploaded.keys():
    path = fn
    img = image.load_img(path, target_size=(150, 150))
    imgplot = plt.imshow(img)

    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)

    images = np.vstack([x])
    classes = model.predict(images, batch_size=10)

    print(fn)
    print(classes)

# Predict based on highest categorical score
    if classes[0, 0] != 0:
        print('Paper')
    elif classes[0, 1] != 0:
        print('Rock')
    else:
        print('Scissors')